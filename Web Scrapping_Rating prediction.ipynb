{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8501041d",
   "metadata": {},
   "source": [
    "# RATINGS PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97280430",
   "metadata": {},
   "source": [
    "# PROBLEM STATEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc5785",
   "metadata": {},
   "source": [
    "We have a client who has a website where people write different reviews for technical products. \n",
    "Now they are adding a new feature to their website i.e. The reviewer will have to add stars(rating) \n",
    "as well with the review. The rating is out 5 stars and it only has 5 options available 1 star, 2 stars, \n",
    "3 stars, 4 stars, 5 stars. Now they want to predict ratings for the reviews which were written in the \n",
    "past and they don’t have a rating. So, we have to build an application which can predict the rating \n",
    "by seeing the review.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e74dc8",
   "metadata": {},
   "source": [
    "# Data Collection Phase "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c3e3c",
   "metadata": {},
   "source": [
    "You have to scrape at least 20000 rows of data. You can scrape more data as well, it’s up to you. \n",
    "more the data better the model\n",
    "In this section you need to scrape the reviews of different laptops, Phones, Headphones, smart \n",
    "watches, Professional Cameras, Printers, Monitors, Home theater, Router from different e\u0002commerce websites.\n",
    "Basically, we need these columns\u0002\n",
    "\n",
    "1) reviews of the product.\n",
    "\n",
    "2) rating of the product.\n",
    "\n",
    "You can fetch other data as well, if you think data can be useful or can help in the project. It \n",
    "completely depends on your imagination or assumption.\n",
    "\n",
    "\n",
    "\n",
    "Hint:\n",
    "\n",
    "• Try to fetch data from different websites. If data is from different websites, it will help our \n",
    "model to remove the effect of over fitting.\n",
    "\n",
    "• Try to fetch an equal number of reviews for each rating, for example if you are fetching\n",
    "10000 reviews then all ratings 1,2,3,4,5 should be 2000. It will balance our data set.\n",
    "\n",
    "• Convert all the ratings to their round number, as there are only 5 options for rating i.e., \n",
    "1,2,3,4,5. If a rating is 4.5 convert it 5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19ca17",
   "metadata": {},
   "source": [
    "# Model Building Phase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447fbc6",
   "metadata": {},
   "source": [
    "After collecting the data, you need to build a machine learning model. Before model building do \n",
    "all data preprocessing steps involving NLP. Try different models with different hyper parameters \n",
    "and select the best model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda15970",
   "metadata": {},
   "source": [
    "Follow the complete life cycle of data science. Include all the steps like\u0002\n",
    "\n",
    "1. Data Cleaning\n",
    "\n",
    "2. Exploratory Data Analysis\n",
    "\n",
    "3. Data Preprocessing\n",
    "\n",
    "4. Model Building\n",
    "\n",
    "5. Model Evaluation\n",
    "\n",
    "6. Selecting the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90adcb",
   "metadata": {},
   "source": [
    "# WEB SCRAPING (RATING PREDICTION):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a10da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessory libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482fdc59",
   "metadata": {},
   "source": [
    "# Scrapping Ratings and Reviews from Flipkart.com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1409785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to web driver\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60fc387",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "#clicking on cancel buttopn \n",
    "driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b70bcc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "srch_items = ['laptops', 'Phones','smart watches','Monitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61cbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "review_text = []\n",
    "ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e36781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap():    \n",
    "        for i in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "            review_text.append(i.text)\n",
    "        for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "            title.append(i.text)\n",
    "        for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']/../div\"):\n",
    "            ratings.append(i.text)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a819c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01054932",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in srch_items:\n",
    "    #Find search bar\n",
    "    srchBar = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    srchBar.clear()\n",
    "    srchBar.send_keys(i)\n",
    "    #clicking on search button\n",
    "    driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()\n",
    "    time.sleep(3)\n",
    "    page = []\n",
    "    for i in driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\"):\n",
    "        page.append(i.get_attribute('href'))\n",
    "    for i in page[0:4]:\n",
    "        driver.get(i)\n",
    "        time.sleep(3)\n",
    "        items = driver.find_elements_by_xpath(\"//a[@class='_1fQZEK']\")\n",
    "        for i in items:\n",
    "            urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9715ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "597e88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    for _ in range(2):\n",
    "        driver.execute_script(\"window.scrollBy(0,6000)\")\n",
    "        time.sleep(1)\n",
    "        #clicking on all reviews\n",
    "    try:\n",
    "        btn=driver.find_element_by_xpath(\"//div[@class='_2c2kV-']/following::a\")\n",
    "        lnk = btn.get_attribute('href')\n",
    "        driver.get(lnk)\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    scrap()        \n",
    "    try:\n",
    "        n_page=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "        np=[]\n",
    "        for i in n_page:\n",
    "            np.append(i.get_attribute('href'))\n",
    "        for i in np[0:18]:\n",
    "            driver.get(i)\n",
    "            time.sleep(1)\n",
    "            scrap()\n",
    "    except: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb81365a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings), len(review_text), len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292e4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa6b89b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Reiew_Text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Review_Title, Reiew_Text, Ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "data = list(zip(title,review_text,ratings))\n",
    "df2 = pd.DataFrame(data, columns = [\"Review_Title\",\"Reiew_Text\",\"Ratings\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6d404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50680352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the data into csv file\n",
    "df2.to_csv(\"flipkrt1_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e69cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d7076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
